{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import plotly.express as px\n",
    "import plotly\n",
    "\n",
    "import re\n",
    "\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.manifold import TSNE, Isomap\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.cluster import (KMeans, SpectralClustering, \n",
    "                             MiniBatchKMeans, AgglomerativeClustering)\n",
    "\n",
    "from sklearn.metrics import (davies_bouldin_score, \n",
    "                            silhouette_score,\n",
    "                            calinski_harabasz_score,\n",
    "                            homogeneity_score)\n",
    "\n",
    "from utils.portfolio import MarkowitzPortfolio, backtesting_universal\n",
    "from utils.portfolio_metrics import (calculate_measures, show_drawdown_recovery, \n",
    "                                     find_max_recovery, find_max_drawdown)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import plotly.express as px\n",
    "import plotly\n",
    "\n",
    "from utils.portfolio_metrics import calculate_measures, show_drawdown_recovery\n",
    "from datetime import datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/config.json', 'r') as file:\n",
    "    config = json.load(file)\n",
    "    \n",
    "rs = config['random_state']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(482, 1196)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2018-01-03</th>\n",
       "      <th>2018-01-04</th>\n",
       "      <th>2018-01-05</th>\n",
       "      <th>2018-01-08</th>\n",
       "      <th>2018-01-09</th>\n",
       "      <th>2018-01-10</th>\n",
       "      <th>2018-01-11</th>\n",
       "      <th>2018-01-12</th>\n",
       "      <th>2018-01-16</th>\n",
       "      <th>2018-01-17</th>\n",
       "      <th>...</th>\n",
       "      <th>2022-09-20</th>\n",
       "      <th>2022-09-21</th>\n",
       "      <th>2022-09-22</th>\n",
       "      <th>2022-09-23</th>\n",
       "      <th>2022-09-26</th>\n",
       "      <th>2022-09-27</th>\n",
       "      <th>2022-09-28</th>\n",
       "      <th>2022-09-29</th>\n",
       "      <th>2022-09-30</th>\n",
       "      <th>sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.025444</td>\n",
       "      <td>-0.007501</td>\n",
       "      <td>0.015988</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>0.024554</td>\n",
       "      <td>-0.013655</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.013136</td>\n",
       "      <td>-0.006971</td>\n",
       "      <td>0.011652</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019737</td>\n",
       "      <td>-0.012955</td>\n",
       "      <td>-0.016524</td>\n",
       "      <td>-0.007316</td>\n",
       "      <td>-0.009475</td>\n",
       "      <td>-0.005723</td>\n",
       "      <td>0.017351</td>\n",
       "      <td>-0.007921</td>\n",
       "      <td>-0.009695</td>\n",
       "      <td>Healthcare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAL</th>\n",
       "      <td>-0.012266</td>\n",
       "      <td>0.006305</td>\n",
       "      <td>-0.000380</td>\n",
       "      <td>-0.009877</td>\n",
       "      <td>-0.000959</td>\n",
       "      <td>0.032642</td>\n",
       "      <td>0.049089</td>\n",
       "      <td>0.036335</td>\n",
       "      <td>-0.008380</td>\n",
       "      <td>0.003105</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016889</td>\n",
       "      <td>-0.052971</td>\n",
       "      <td>-0.039305</td>\n",
       "      <td>-0.039339</td>\n",
       "      <td>-0.028665</td>\n",
       "      <td>0.034570</td>\n",
       "      <td>0.039120</td>\n",
       "      <td>-0.039216</td>\n",
       "      <td>-0.017143</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAP</th>\n",
       "      <td>0.009049</td>\n",
       "      <td>0.036899</td>\n",
       "      <td>0.010631</td>\n",
       "      <td>-0.007042</td>\n",
       "      <td>-0.008080</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>0.021340</td>\n",
       "      <td>0.026472</td>\n",
       "      <td>-0.017595</td>\n",
       "      <td>0.012730</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013735</td>\n",
       "      <td>-0.002231</td>\n",
       "      <td>-0.008399</td>\n",
       "      <td>-0.021997</td>\n",
       "      <td>-0.017570</td>\n",
       "      <td>0.010337</td>\n",
       "      <td>0.025171</td>\n",
       "      <td>-0.022410</td>\n",
       "      <td>-0.020794</td>\n",
       "      <td>Consumer Cyclical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.004645</td>\n",
       "      <td>0.011385</td>\n",
       "      <td>-0.003714</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>-0.000229</td>\n",
       "      <td>0.005680</td>\n",
       "      <td>0.010326</td>\n",
       "      <td>-0.005082</td>\n",
       "      <td>0.016516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015665</td>\n",
       "      <td>-0.020268</td>\n",
       "      <td>-0.006375</td>\n",
       "      <td>-0.015124</td>\n",
       "      <td>0.002260</td>\n",
       "      <td>0.006566</td>\n",
       "      <td>-0.012652</td>\n",
       "      <td>-0.049119</td>\n",
       "      <td>-0.030039</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABBV</th>\n",
       "      <td>0.015649</td>\n",
       "      <td>-0.005703</td>\n",
       "      <td>0.017408</td>\n",
       "      <td>-0.016022</td>\n",
       "      <td>0.007538</td>\n",
       "      <td>-0.005487</td>\n",
       "      <td>-0.004213</td>\n",
       "      <td>0.010779</td>\n",
       "      <td>0.021427</td>\n",
       "      <td>0.018246</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006239</td>\n",
       "      <td>-0.010298</td>\n",
       "      <td>0.019243</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>-0.012932</td>\n",
       "      <td>0.003612</td>\n",
       "      <td>0.020322</td>\n",
       "      <td>-0.013001</td>\n",
       "      <td>-0.059627</td>\n",
       "      <td>Healthcare</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1196 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      2018-01-03  2018-01-04  2018-01-05  2018-01-08  2018-01-09  2018-01-10  \\\n",
       "A       0.025444   -0.007501    0.015988    0.002146    0.024554   -0.013655   \n",
       "AAL    -0.012266    0.006305   -0.000380   -0.009877   -0.000959    0.032642   \n",
       "AAP     0.009049    0.036899    0.010631   -0.007042   -0.008080    0.000905   \n",
       "AAPL   -0.000174    0.004645    0.011385   -0.003714   -0.000115   -0.000229   \n",
       "ABBV    0.015649   -0.005703    0.017408   -0.016022    0.007538   -0.005487   \n",
       "\n",
       "      2018-01-11  2018-01-12  2018-01-16  2018-01-17  ...  2022-09-20  \\\n",
       "A       0.000141    0.013136   -0.006971    0.011652  ...   -0.019737   \n",
       "AAL     0.049089    0.036335   -0.008380    0.003105  ...   -0.016889   \n",
       "AAP     0.021340    0.026472   -0.017595    0.012730  ...   -0.013735   \n",
       "AAPL    0.005680    0.010326   -0.005082    0.016516  ...    0.015665   \n",
       "ABBV   -0.004213    0.010779    0.021427    0.018246  ...   -0.006239   \n",
       "\n",
       "      2022-09-21  2022-09-22  2022-09-23  2022-09-26  2022-09-27  2022-09-28  \\\n",
       "A      -0.012955   -0.016524   -0.007316   -0.009475   -0.005723    0.017351   \n",
       "AAL    -0.052971   -0.039305   -0.039339   -0.028665    0.034570    0.039120   \n",
       "AAP    -0.002231   -0.008399   -0.021997   -0.017570    0.010337    0.025171   \n",
       "AAPL   -0.020268   -0.006375   -0.015124    0.002260    0.006566   -0.012652   \n",
       "ABBV   -0.010298    0.019243    0.000350   -0.012932    0.003612    0.020322   \n",
       "\n",
       "      2022-09-29  2022-09-30             sector  \n",
       "A      -0.007921   -0.009695         Healthcare  \n",
       "AAL    -0.039216   -0.017143        Industrials  \n",
       "AAP    -0.022410   -0.020794  Consumer Cyclical  \n",
       "AAPL   -0.049119   -0.030039         Technology  \n",
       "ABBV   -0.013001   -0.059627         Healthcare  \n",
       "\n",
       "[5 rows x 1196 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(config['ticker_data_preprocessed'], index_col=0)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABC</th>\n",
       "      <th>ABMD</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ADI</th>\n",
       "      <th>...</th>\n",
       "      <th>WYNN</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XOM</th>\n",
       "      <th>XRAY</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZBRA</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>0.025444</td>\n",
       "      <td>-0.012266</td>\n",
       "      <td>0.009049</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.015649</td>\n",
       "      <td>0.003722</td>\n",
       "      <td>0.017300</td>\n",
       "      <td>0.002211</td>\n",
       "      <td>0.004615</td>\n",
       "      <td>0.012406</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010834</td>\n",
       "      <td>-0.006693</td>\n",
       "      <td>0.019640</td>\n",
       "      <td>-0.003426</td>\n",
       "      <td>0.012193</td>\n",
       "      <td>-0.000858</td>\n",
       "      <td>0.006932</td>\n",
       "      <td>0.019863</td>\n",
       "      <td>-0.001183</td>\n",
       "      <td>0.004598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>-0.007501</td>\n",
       "      <td>0.006305</td>\n",
       "      <td>0.036899</td>\n",
       "      <td>0.004645</td>\n",
       "      <td>-0.005703</td>\n",
       "      <td>-0.002225</td>\n",
       "      <td>0.017516</td>\n",
       "      <td>-0.001697</td>\n",
       "      <td>0.011841</td>\n",
       "      <td>-0.001094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005415</td>\n",
       "      <td>-0.007791</td>\n",
       "      <td>0.001384</td>\n",
       "      <td>-0.000149</td>\n",
       "      <td>0.006676</td>\n",
       "      <td>0.010180</td>\n",
       "      <td>-0.001441</td>\n",
       "      <td>0.019760</td>\n",
       "      <td>0.004147</td>\n",
       "      <td>0.005964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>0.015988</td>\n",
       "      <td>-0.000380</td>\n",
       "      <td>0.010631</td>\n",
       "      <td>0.011385</td>\n",
       "      <td>0.017408</td>\n",
       "      <td>0.012104</td>\n",
       "      <td>0.015408</td>\n",
       "      <td>0.002890</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>0.004053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006671</td>\n",
       "      <td>-0.007003</td>\n",
       "      <td>-0.000806</td>\n",
       "      <td>0.014051</td>\n",
       "      <td>-0.001874</td>\n",
       "      <td>0.005828</td>\n",
       "      <td>0.009941</td>\n",
       "      <td>0.015576</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.011444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>0.002146</td>\n",
       "      <td>-0.009877</td>\n",
       "      <td>-0.007042</td>\n",
       "      <td>-0.003714</td>\n",
       "      <td>-0.016022</td>\n",
       "      <td>0.016576</td>\n",
       "      <td>0.027086</td>\n",
       "      <td>-0.002882</td>\n",
       "      <td>0.007991</td>\n",
       "      <td>0.001745</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013314</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.004496</td>\n",
       "      <td>0.006781</td>\n",
       "      <td>0.003611</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.009951</td>\n",
       "      <td>-0.004914</td>\n",
       "      <td>0.011996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09</th>\n",
       "      <td>0.024554</td>\n",
       "      <td>-0.000959</td>\n",
       "      <td>-0.008080</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>0.007538</td>\n",
       "      <td>0.006398</td>\n",
       "      <td>0.009432</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.003335</td>\n",
       "      <td>-0.002069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006778</td>\n",
       "      <td>-0.011667</td>\n",
       "      <td>-0.004246</td>\n",
       "      <td>-0.041728</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>-0.002651</td>\n",
       "      <td>-0.016083</td>\n",
       "      <td>0.030643</td>\n",
       "      <td>0.023509</td>\n",
       "      <td>0.011719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 482 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A       AAL       AAP      AAPL      ABBV       ABC  \\\n",
       "2018-01-03  0.025444 -0.012266  0.009049 -0.000174  0.015649  0.003722   \n",
       "2018-01-04 -0.007501  0.006305  0.036899  0.004645 -0.005703 -0.002225   \n",
       "2018-01-05  0.015988 -0.000380  0.010631  0.011385  0.017408  0.012104   \n",
       "2018-01-08  0.002146 -0.009877 -0.007042 -0.003714 -0.016022  0.016576   \n",
       "2018-01-09  0.024554 -0.000959 -0.008080 -0.000115  0.007538  0.006398   \n",
       "\n",
       "                ABMD       ABT       ACN       ADI  ...      WYNN       XEL  \\\n",
       "2018-01-03  0.017300  0.002211  0.004615  0.012406  ... -0.010834 -0.006693   \n",
       "2018-01-04  0.017516 -0.001697  0.011841 -0.001094  ...  0.005415 -0.007791   \n",
       "2018-01-05  0.015408  0.002890  0.008249  0.004053  ...  0.006671 -0.007003   \n",
       "2018-01-08  0.027086 -0.002882  0.007991  0.001745  ... -0.013314  0.007480   \n",
       "2018-01-09  0.009432  0.001700  0.003335 -0.002069  ...  0.006778 -0.011667   \n",
       "\n",
       "                 XOM      XRAY       XYL       YUM       ZBH      ZBRA  \\\n",
       "2018-01-03  0.019640 -0.003426  0.012193 -0.000858  0.006932  0.019863   \n",
       "2018-01-04  0.001384 -0.000149  0.006676  0.010180 -0.001441  0.019760   \n",
       "2018-01-05 -0.000806  0.014051 -0.001874  0.005828  0.009941  0.015576   \n",
       "2018-01-08  0.004496  0.006781  0.003611  0.001690  0.001905  0.009951   \n",
       "2018-01-09 -0.004246 -0.041728  0.000288 -0.002651 -0.016083  0.030643   \n",
       "\n",
       "                ZION       ZTS  \n",
       "2018-01-03 -0.001183  0.004598  \n",
       "2018-01-04  0.004147  0.005964  \n",
       "2018-01-05  0.000393  0.011444  \n",
       "2018-01-08 -0.004914  0.011996  \n",
       "2018-01-09  0.023509  0.011719  \n",
       "\n",
       "[5 rows x 482 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pct = df.drop(['sector'], axis=1).T\n",
    "df_pct.index = pd.to_datetime(df_pct.index)\n",
    "\n",
    "tickers_list = df_pct.columns.tolist()\n",
    "\n",
    "df_pct.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Date'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_market = pd.read_csv(config['ticker_data_sp500'], index_col=0)\n",
    "df_market.index = pd.to_datetime(df_market.index)\n",
    "df_market = df_market.pct_change()\n",
    "df_market.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticker    492\n",
       "sector     11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sectors = pd.read_csv(config['tickers_sectors_path'], index_col=0)\n",
    "df_sectors.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = df.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feats_tsne = TSNE(n_components=2).fit_transform(df.drop(['sector'], axis=1))\n",
    "# df_tsne = pd.DataFrame({'axis0':feats_tsne[:, 0],'axis1':feats_tsne[:, 1],'sector':df['sector']})\n",
    "\n",
    "# fig = px.scatter(df_tsne, x = 'axis0', y = 'axis1', color=\"sector\", width=800, height=600)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator(parameters):\n",
    "    if not parameters:\n",
    "        yield dict()\n",
    "    else:\n",
    "        key_to_iterate = list(parameters.keys())[0]\n",
    "        next_round_parameters = {p : parameters[p]\n",
    "                    for p in parameters if p != key_to_iterate}\n",
    "        for val in parameters[key_to_iterate]:\n",
    "            for pars in make_generator(next_round_parameters):\n",
    "                temp_res = pars\n",
    "                temp_res[key_to_iterate] = val\n",
    "                yield temp_res\n",
    "\n",
    "\n",
    "class ClusteringGridSearch:\n",
    "    def __init__(self, estimator, param_grid, scoring):\n",
    "\n",
    "        self.estimator = estimator\n",
    "        self.param_grid = param_grid\n",
    "        self.scoring = scoring\n",
    "        \n",
    "        self.best_params_=dict()\n",
    "        self.best_estimator_ = None\n",
    "        self.best_score_ = - 1e-8\n",
    "        \n",
    "    def fit(self, X):\n",
    "        all_params = self.estimator.get_params()\n",
    "        \n",
    "        for params in make_generator(self.param_grid):\n",
    "            \n",
    "            all_params.update(params)\n",
    "            self.estimator = self.estimator.set_params(**all_params)\n",
    "#             self.estimator.fit(X)\n",
    "#             labels = self.estimator.labels_\n",
    "            score = self.scoring(self.estimator, X)\n",
    "    \n",
    "            if score > self.best_score_:\n",
    "                self.best_score_ = score\n",
    "                self.best_estimator_ = self.estimator.fit(X)\n",
    "                self.best_params_ = params\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(models_dict, df_pct):\n",
    "    embeddings_dict = dict()\n",
    "    \n",
    "    for model_name, model in models_dict.items():\n",
    "        embeddings_dict[model_name] = model.transform(df_pct)\n",
    "        \n",
    "    return embeddings_dict\n",
    "\n",
    "def get_clusters(data,\n",
    "                 tickers_list,\n",
    "                 clust_model,\n",
    "                 make_grid=False, \n",
    "                 grid_params=None,\n",
    "                 grid_metric=None):\n",
    "    #TO DO Make grid search\n",
    "    \n",
    "    \n",
    "    if make_grid:\n",
    "        grid_model = ClusteringGridSearch(estimator=clust_model, param_grid=grid_params,\n",
    "                                            scoring=grid_metric)\n",
    "        grid_model.fit(data)\n",
    "        clust_model = grid_model.best_estimator_\n",
    "    else:\n",
    "        clust_model.fit(data)\n",
    "    df_clusters = pd.DataFrame([tickers_list, clust_model.labels_], index=['ticker', 'cluster']).T\n",
    "    return df_clusters\n",
    "\n",
    "\n",
    "def select_assets(df_clusters, df_pct, selection_method, n_save=2, **kargs):\n",
    "\n",
    "    selected_tickers = []\n",
    "    for cluster in np.unique(df_clusters['cluster'].values):\n",
    "\n",
    "        df_clusters_loc = df_clusters[df_clusters['cluster'] == cluster]\n",
    "        list_tickers = df_clusters_loc['ticker'].values.tolist()\n",
    "        selected_tickers_loc = selection_method(list_tickers, n_save=n_save, df_pct=df_pct, **kargs)\n",
    "        selected_tickers.extend(selected_tickers_loc)\n",
    "        \n",
    "    return selected_tickers\n",
    "\n",
    "def get_train_test_data(df_pct,\n",
    "                        train_start_per, \n",
    "                        window_train, \n",
    "                        window_test):\n",
    "    \n",
    "    # slicing data train\n",
    "            \n",
    "    train_finish_per = train_start_per + window_train\n",
    "\n",
    "    train_year_start_per = train_start_per // 12\n",
    "    train_month_start_per = train_start_per % 12 + 1\n",
    "\n",
    "    train_year_finish_per = train_finish_per // 12\n",
    "    train_month_finish_per = train_finish_per % 12 + 1\n",
    "\n",
    "    mask_train = (df_pct.index > datetime(train_year_start_per, train_month_start_per, 1))\n",
    "    mask_train = mask_train & (df_pct.index < datetime(train_year_finish_per, train_month_finish_per, 1))\n",
    "    df_train = df_pct[mask_train]\n",
    "\n",
    "    # slicing data test\n",
    "    \n",
    "    test_finish_per = train_finish_per + window_test\n",
    "    \n",
    "    test_year_start_per = train_year_finish_per\n",
    "    test_month_start_per = train_month_finish_per\n",
    "\n",
    "    test_year_finish_per = test_finish_per // 12\n",
    "    test_month_finish_per = test_finish_per % 12 + 1\n",
    "\n",
    "    #print(train_year_start_per, train_month_start_per,  train_year_finish_per, train_month_finish_per, test_year_finish_per, test_month_finish_per)\n",
    "\n",
    "    mask_test = (df_pct.index > datetime(test_year_start_per, test_month_start_per, 1)) \n",
    "    mask_test = mask_test & (df_pct.index < datetime(test_year_finish_per, test_month_finish_per, 1))\n",
    "    df_test = df_pct[mask_test]\n",
    "    \n",
    "    return df_train, df_test\n",
    "\n",
    "\n",
    "def backtesting_one_model(df_pct, # df with pct_changes: columns - tick, index - date\n",
    "                        port_model=MarkowitzPortfolio, #portfolio estimation function\n",
    "                        window_train=24, # size of train window in months\n",
    "                        window_test=1,  # size of train window in months\n",
    "                        train_start_year=2018, #start data year\n",
    "                        train_start_month=1, #start data month \n",
    "                        test_finish_year=2022, #end data year\n",
    "                        test_finish_month=11, #end data month\n",
    "                        **kargs):\n",
    "    \n",
    "    weights_all = []\n",
    "    return_portfolio = pd.DataFrame([])\n",
    "    \n",
    "    train_start_month = train_start_year * 12 + train_start_month - 1 #indexing from 0\n",
    "    test_finish_month = test_finish_year * 12 + test_finish_month - 1 #indexing from 0\n",
    "    train_finish_month = test_finish_month - window_train - window_test + 1\n",
    "    \n",
    "    for train_start_per in range(train_start_month, train_finish_month, window_test):\n",
    "        \n",
    "        df_train, df_test = get_train_test_data(df_pct, train_start_per, window_train, window_test)\n",
    "        \n",
    "        mu = (((df_train + 1).prod()) ** (1 / len(df_train)) - 1).values * 252  # средняя доходность за год (252 раб дня)\n",
    "        Sigma = df_train.cov().values * 252  # ковариационная матрица за год (252 раб дня)\n",
    "\n",
    "        port_ = port_model(mu, Sigma, kargs=kargs)\n",
    "        weights, _ = port_.fit()\n",
    "        \n",
    "        weights_all.append(weights)\n",
    "        \n",
    "        return_portfolio_loc = pd.DataFrame(df_test.values @ weights, index=df_test.index)\n",
    "        return_portfolio = pd.concat([return_portfolio, return_portfolio_loc])\n",
    "            \n",
    "    return weights_all, return_portfolio\n",
    "\n",
    "def clustering_estimation(X, labels):\n",
    "    scores = []\n",
    "    scores.append(davies_bouldin_score(X, labels)) # Davies-Bouldin Index\n",
    "    scores.append(calinski_harabasz_score(X, labels)) # Calinski Harabaz Index\n",
    "    scores.append(silhouette_score(X, labels)) # Silhouette Coefficient\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_pipeline(df_pct,\n",
    "                     df_market,\n",
    "                     embedding_data,\n",
    "                     \n",
    "                     clust_params,\n",
    "                     selection_params,\n",
    "                     backtesting_params,\n",
    "                    ):\n",
    "    \n",
    "    tickers_list = df_pct.columns.tolist()\n",
    "    \n",
    "    #make clustering\n",
    "    df_clusters = get_clusters(embedding_data, tickers_list, **clust_params)\n",
    "    clust_metrics = clustering_estimation(df_pct.T.values, df_clusters['cluster'])\n",
    "    \n",
    "    #stock selection\n",
    "    selected_tickers = select_assets(df_clusters, df_pct, **selection_params)\n",
    "    \n",
    "    df_pct_loc = df_pct.copy()\n",
    "    df_pct_loc = df_pct_loc[selected_tickers]\n",
    "    \n",
    "    #port_modelling\n",
    "    weights_all, return_portfolio = backtesting_one_model(df_pct_loc, # df with pct_changes: columns - tick, index - date\n",
    "                        **backtesting_params)\n",
    "    \n",
    "    return weights_all, return_portfolio, clust_metrics\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_score(estimator, X, y=None):\n",
    "    estimator.fit(X)\n",
    "    labels_predicted = estimator.labels_\n",
    "    score = silhouette_score(X, labels_predicted)\n",
    "    return score\n",
    "\n",
    "def selection_sharp(list_tickers, n_save, df_pct, riskfree_rate):\n",
    "    df_pct = df_pct[list_tickers]\n",
    "    \n",
    "    sharp = (df_pct.mean() - riskfree_rate)/df_pct.std()\n",
    "    selected_tickers = sharp.sort_values(ascending=False).head(n_save).index.tolist()\n",
    "    \n",
    "    return selected_tickers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dict =  {'pca': PCA(n_components=100, random_state=rs).fit_transform(df.drop(['sector'], axis=1)),\n",
    "            'fast_ica': FastICA(n_components=100, random_state=rs).fit_transform(df.drop(['sector'], axis=1))\n",
    "            }\n",
    "\n",
    "tickers = df.index.tolist()\n",
    "\n",
    "df_conv = pd.read_csv(config['nn_conv_data'], index_col=0).loc[tickers]\n",
    "df_mlp = pd.read_csv(config['nn_mlp_data'], index_col=0).loc[tickers]\n",
    "df_lstm = pd.read_csv(config['nn_lstm_data'], index_col=0).loc[tickers]\n",
    "\n",
    "emb_dict['neural_conv'] = df_conv.values\n",
    "emb_dict['neural_mlp'] = df_mlp.values\n",
    "emb_dict['neural_lstm'] = df_lstm.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0: loss=3.623498233159383\n",
      "Epoch #1: loss=3.594729510943095\n",
      "Epoch #2: loss=3.5778391202290853\n",
      "Epoch #3: loss=3.563490295410156\n",
      "Epoch #4: loss=3.5092859427134195\n",
      "Epoch #5: loss=3.546148983637492\n",
      "Epoch #6: loss=3.5954375982284548\n",
      "Epoch #7: loss=3.465514890352885\n",
      "Epoch #8: loss=3.5493520498275757\n",
      "Epoch #9: loss=3.556980570157369\n",
      "Epoch #10: loss=3.4642389456431073\n",
      "Epoch #11: loss=3.532337522506714\n",
      "Epoch #12: loss=3.562062382698059\n",
      "Epoch #13: loss=3.528723136583964\n",
      "Epoch #14: loss=3.4687657833099363\n",
      "Epoch #15: loss=3.4695447365442913\n",
      "Epoch #16: loss=3.4112135966618857\n",
      "Epoch #17: loss=3.5059076150258384\n",
      "Epoch #18: loss=3.3783089319864907\n",
      "Epoch #19: loss=3.468660497665405\n"
     ]
    }
   ],
   "source": [
    "from ts2vec.ts2vec import TS2Vec\n",
    "\n",
    "data = np.expand_dims(df_pct.values.T, axis=2)\n",
    "\n",
    "# Train a TS2Vec model\n",
    "model = TS2Vec(\n",
    "    input_dims=1,\n",
    "    device=0,\n",
    "    output_dims=100\n",
    ")\n",
    "loss_log = model.fit(\n",
    "    data,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "emb_dict['ts2vec'] = model.encode(data, encoding_window='full_series')  # n_instances x output_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca 0 (482, 100)\n",
      "fast_ica 0 (482, 100)\n",
      "neural_conv 0 (482, 100)\n",
      "neural_mlp 0 (482, 100)\n",
      "neural_lstm 0 (482, 100)\n",
      "ts2vec 0 (482, 100)\n"
     ]
    }
   ],
   "source": [
    "for method_name, data in emb_dict.items():\n",
    "    print(method_name, np.sum(np.isnan(data)), data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "riskfree = config['riskless_rate']\n",
    "riskfree_rate=(1 + riskfree) **(1/252) - 1,\n",
    "ret_det=(1 + 0.03) **(1/252) - 1,\n",
    "    \n",
    "    \n",
    "clust_params = {'clust_model':KMeans(n_clusters=11, random_state=42),\n",
    "                'make_grid':False, \n",
    "                'grid_params':{\n",
    "                   'n_clusters':np.arange(9, 14),\n",
    "                   'init': ['k-means++', 'random'],\n",
    "                   'algorithm':['auto', 'full', 'elkan']\n",
    "                },\n",
    "                'grid_metric':custom_score}\n",
    "\n",
    "\n",
    "selection_params = {'selection_method':selection_sharp,\n",
    "                    'n_save':2, \n",
    "                    'riskfree_rate':riskfree_rate,}\n",
    "\n",
    "backtesting_params = {'port_model':MarkowitzPortfolio,\n",
    "                      'window_train':24, # size of train window in months\n",
    "                      'window_test':1,  # size of train window in months\n",
    "                       \n",
    "                      'train_start_year':2018, #start data year\n",
    "                      'train_start_month':1, #start data month \n",
    "                      'test_finish_year':2022, #end data year\n",
    "                      'test_finish_month':11, #end data month\n",
    "                      'ret_det':ret_det\n",
    "                     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c83d6a2cff8436bab81b5dc227df1d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cluster_metrics_df = pd.DataFrame() \n",
    "port_df = pd.DataFrame()    #Считаем портфель Марковица для всех методов кластеризации\n",
    "dict_weight_methods = dict()\n",
    "\n",
    "for model_name, embedding_data in tqdm(emb_dict.items()):\n",
    "    \n",
    "    weights_all, return_portfolio, cluster_metrics = general_pipeline(\n",
    "        df_pct,\n",
    "        df_market,\n",
    "        embedding_data=embedding_data,\n",
    "        clust_params=clust_params,\n",
    "        selection_params=selection_params,\n",
    "        backtesting_params=backtesting_params)\n",
    "    \n",
    "    cluster_metrics_df[model_name] = cluster_metrics\n",
    "    port_df[model_name] = return_portfolio\n",
    "    dict_weight_methods[model_name] = weights_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_df['sp500'] = df_market.loc[port_df.index] \n",
    "\n",
    "# economic sectors\n",
    "clust_econ_sectors = LabelEncoder().fit_transform(df['sector'])\n",
    "df_clusters = pd.DataFrame([tickers_list, clust_econ_sectors], index=['ticker', 'cluster']).T\n",
    "\n",
    "\n",
    "selected_tickers = select_assets(df_clusters, df_pct, **selection_params)\n",
    "df_pct_loc = df_pct[selected_tickers]\n",
    "weights_all, return_portfolio = backtesting_one_model(df_pct_loc, # df with pct_changes: columns - tick, index - date\n",
    "                    **backtesting_params)\n",
    "\n",
    "cluster_metrics_df['sectors'] = clustering_estimation(df_pct.T.values, df_clusters['cluster'])\n",
    "dict_weight_methods['sectors'] = weights_all\n",
    "port_df['sectors'] = return_portfolio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# results estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(port_df, df_market, riskfree_rate, port_name='Markovitz'):\n",
    "    \n",
    "    result_df = pd.DataFrame()\n",
    "    \n",
    "    #Average daily returns\n",
    "    mean = port_df.mean()\n",
    "    result_df['AVG_returns'] = mean \n",
    "\n",
    "    #Risk\n",
    "    risk = port_df.std()\n",
    "    result_df['Risk'] = risk\n",
    "\n",
    "    #Beta\n",
    "    var_ = port_df.var()\n",
    "    cov_ = port_df.cov()\n",
    "    beta = cov_['sp500']/var_\n",
    "\n",
    "    result_df['Beta'] = beta\n",
    "\n",
    "    #Alpha\n",
    "    alpha = mean - (riskfree_rate + beta*(result_df.loc['sp500', 'AVG_returns'] - riskfree_rate))\n",
    "    result_df['Alpha'] = alpha\n",
    "    \n",
    "    #Sharpe \n",
    "    sharpe = (mean - riskfree_rate)/risk\n",
    "    result_df['Sharpe'] = sharpe\n",
    "\n",
    "    #VaR(95%)\n",
    "    VaR = - risk*1.65\n",
    "    result_df['VaR(95%)'] = VaR\n",
    "    \n",
    "    #Drawdown and Recovery\n",
    "    portfolio_value = (port_df+1).cumprod() #датафрейм со \"стоимостью\" портфеля\n",
    "\n",
    "    recovery = []\n",
    "    drawdown = []\n",
    "    for i in range(len(port_df.columns)):\n",
    "        recovery.append(find_max_recovery(portfolio_value.iloc[:,i])[0])\n",
    "        drawdown.append(find_max_drawdown(portfolio_value.iloc[:,i])[0])\n",
    "    \n",
    "    result_df['Drawdown(%)'] = drawdown\n",
    "    result_df['Recovery(days)'] = recovery\n",
    "     \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AVG_returns</th>\n",
       "      <th>Risk</th>\n",
       "      <th>Beta</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Sharpe</th>\n",
       "      <th>VaR(95%)</th>\n",
       "      <th>Drawdown(%)</th>\n",
       "      <th>Recovery(days)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pca</th>\n",
       "      <td>0.001365</td>\n",
       "      <td>0.023348</td>\n",
       "      <td>0.527565</td>\n",
       "      <td>1.169806e-03</td>\n",
       "      <td>0.053431</td>\n",
       "      <td>-0.038524</td>\n",
       "      <td>-52.642869</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fast_ica</th>\n",
       "      <td>-0.000010</td>\n",
       "      <td>0.020395</td>\n",
       "      <td>0.625771</td>\n",
       "      <td>-2.198553e-04</td>\n",
       "      <td>-0.006261</td>\n",
       "      <td>-0.033651</td>\n",
       "      <td>-55.592773</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neural_conv</th>\n",
       "      <td>0.001161</td>\n",
       "      <td>0.023985</td>\n",
       "      <td>0.531067</td>\n",
       "      <td>9.655549e-04</td>\n",
       "      <td>0.043517</td>\n",
       "      <td>-0.039576</td>\n",
       "      <td>-53.319042</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neural_mlp</th>\n",
       "      <td>0.002304</td>\n",
       "      <td>0.029036</td>\n",
       "      <td>0.401290</td>\n",
       "      <td>2.127375e-03</td>\n",
       "      <td>0.075303</td>\n",
       "      <td>-0.047909</td>\n",
       "      <td>-61.967517</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neural_lstm</th>\n",
       "      <td>0.001586</td>\n",
       "      <td>0.020291</td>\n",
       "      <td>0.632199</td>\n",
       "      <td>1.375469e-03</td>\n",
       "      <td>0.072376</td>\n",
       "      <td>-0.033480</td>\n",
       "      <td>-27.793733</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ts2vec</th>\n",
       "      <td>0.001574</td>\n",
       "      <td>0.023195</td>\n",
       "      <td>0.527303</td>\n",
       "      <td>1.379129e-03</td>\n",
       "      <td>0.062805</td>\n",
       "      <td>-0.038273</td>\n",
       "      <td>-47.588698</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sp500</th>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.016120</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.252607e-19</td>\n",
       "      <td>0.009137</td>\n",
       "      <td>-0.026598</td>\n",
       "      <td>-33.924960</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sectors</th>\n",
       "      <td>0.001177</td>\n",
       "      <td>0.020758</td>\n",
       "      <td>0.605734</td>\n",
       "      <td>9.709456e-04</td>\n",
       "      <td>0.051072</td>\n",
       "      <td>-0.034251</td>\n",
       "      <td>-42.313929</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             AVG_returns      Risk      Beta         Alpha    Sharpe  \\\n",
       "pca             0.001365  0.023348  0.527565  1.169806e-03  0.053431   \n",
       "fast_ica       -0.000010  0.020395  0.625771 -2.198553e-04 -0.006261   \n",
       "neural_conv     0.001161  0.023985  0.531067  9.655549e-04  0.043517   \n",
       "neural_mlp      0.002304  0.029036  0.401290  2.127375e-03  0.075303   \n",
       "neural_lstm     0.001586  0.020291  0.632199  1.375469e-03  0.072376   \n",
       "ts2vec          0.001574  0.023195  0.527303  1.379129e-03  0.062805   \n",
       "sp500           0.000265  0.016120  1.000000  3.252607e-19  0.009137   \n",
       "sectors         0.001177  0.020758  0.605734  9.709456e-04  0.051072   \n",
       "\n",
       "             VaR(95%)  Drawdown(%)  Recovery(days)  \n",
       "pca         -0.038524   -52.642869             202  \n",
       "fast_ica    -0.033651   -55.592773             331  \n",
       "neural_conv -0.039576   -53.319042             195  \n",
       "neural_mlp  -0.047909   -61.967517              73  \n",
       "neural_lstm -0.033480   -27.793733              85  \n",
       "ts2vec      -0.038273   -47.588698             192  \n",
       "sp500       -0.026598   -33.924960             179  \n",
       "sectors     -0.034251   -42.313929             185  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_metrics = calc_metrics(port_df, df_market, riskfree_rate)\n",
    "all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DB</th>\n",
       "      <th>HC</th>\n",
       "      <th>Sil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pca</th>\n",
       "      <td>2.994599</td>\n",
       "      <td>18.344697</td>\n",
       "      <td>0.036457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fast_ica</th>\n",
       "      <td>4.119657</td>\n",
       "      <td>4.976354</td>\n",
       "      <td>-0.038924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neural_conv</th>\n",
       "      <td>4.370061</td>\n",
       "      <td>10.041375</td>\n",
       "      <td>-0.017983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neural_mlp</th>\n",
       "      <td>5.336673</td>\n",
       "      <td>8.906414</td>\n",
       "      <td>-0.044381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neural_lstm</th>\n",
       "      <td>7.138803</td>\n",
       "      <td>3.276008</td>\n",
       "      <td>-0.041314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ts2vec</th>\n",
       "      <td>7.341633</td>\n",
       "      <td>6.144513</td>\n",
       "      <td>-0.047008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sectors</th>\n",
       "      <td>3.744944</td>\n",
       "      <td>10.966541</td>\n",
       "      <td>-0.013596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   DB         HC       Sil\n",
       "pca          2.994599  18.344697  0.036457\n",
       "fast_ica     4.119657   4.976354 -0.038924\n",
       "neural_conv  4.370061  10.041375 -0.017983\n",
       "neural_mlp   5.336673   8.906414 -0.044381\n",
       "neural_lstm  7.138803   3.276008 -0.041314\n",
       "ts2vec       7.341633   6.144513 -0.047008\n",
       "sectors      3.744944  10.966541 -0.013596"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_metrics_df = cluster_metrics_df.rename(index=dict(zip(list(range(3)), ['DB', 'HC', 'Sil']))).T\n",
    "cluster_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
